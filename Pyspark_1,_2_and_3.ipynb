{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJaGxUYyv6dawxs5xVo7Kl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthpendal/Pyspark/blob/main/Pyspark_1%2C_2_and_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgjHsMV7kr7R",
        "outputId": "da849e15-2bb6-4cd4-941b-6ecab34a5b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "8pwvpGUzkveR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "vdvCsVAPlN8H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('sparks1').getOrCreate()"
      ],
      "metadata": {
        "id": "3gv6OjAbkzbr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "fAj-5I3WlLGW",
        "outputId": "468f6c3e-1573-4efa-b727-2fbdd34f52eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3d13e52410>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c43a402d3d2c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.5</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>sparks1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=spark.read.csv('/content/sample_data/Srudent_Marks.csv')"
      ],
      "metadata": {
        "id": "UZGfsSUllnIN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g672O4OPl_WX",
        "outputId": "2471a1bf-bd43-4e68-9655-7544b8a34aea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|    _c0|     _c1|    _c2|  _c3|\n",
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark=spark.read.option('header','true').csv('/content/sample_data/Srudent_Marks.csv')"
      ],
      "metadata": {
        "id": "ltFnOu_GmsgE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKntpgu_m9RV",
        "outputId": "c3ec5c4f-38c4-4008-84a1-07b4bc5bd14c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyNpvm3KnATe",
        "outputId": "ee762cf3-e65e-4e34-a79e-b62421781a14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Student: string (nullable = true)\n",
            " |-- Name : string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Marks: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#another mothod to read the file\n",
        "df_pyspark=spark.read.csv('/content/sample_data/Srudent_Marks.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS2sDjSGnlO0",
        "outputId": "5d27b16a-a6cc-455a-a45d-07525755b01e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import IntegerType, StringType, DoubleType, BooleanType, DateType\n",
        "df_spark=df_spark.withColumn('Marks',df_spark['Marks'].cast(IntegerType()))"
      ],
      "metadata": {
        "id": "KmvIPUA0M_ZK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U7YDg06VJrP",
        "outputId": "8c8e9d43-4f1e-48e4-8147-2f777af5bbb1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Student', 'string'),\n",
              " ('Name ', 'string'),\n",
              " ('Subject', 'string'),\n",
              " ('Marks', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYWXbUXM9Wbo",
        "outputId": "7519d64e-04e7-4765-a7ec-e1f141d7ba0d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Student: integer (nullable = true)\n",
            " |-- Name : string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Marks: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "u_CBF78F9uh2",
        "outputId": "d16f2238-ff7c-4a45-ee98-f7a7328742cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htNeKvZz98m0",
        "outputId": "405cc194-320e-441e-c924-b4af6390052a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Student', 'Name ', 'Subject', 'Marks']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eVL4K4c-Ybn",
        "outputId": "506454b3-a5af-4bef-a0f9-0aebe6ad0a70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+-----+\n",
            "|Student| Name |Subject|Marks|\n",
            "+-------+------+-------+-----+\n",
            "|      1|  Mike|Physics|   80|\n",
            "|      2|Jacson|  Maths|   30|\n",
            "|      3|Thomas|Science|   78|\n",
            "+-------+------+-------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYmmOWT0-dkn",
        "outputId": "88ec62d2-ccf5-4724-c670-d5599c8193fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Student=1, Name ='Mike', Subject='Physics', Marks=80),\n",
              " Row(Student=2, Name ='Jacson', Subject='Maths', Marks=30),\n",
              " Row(Student=3, Name ='Thomas', Subject='Science', Marks=78)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOn1PDcT-gh7",
        "outputId": "6b9a0927-25ca-40eb-d39e-0b05ab5165a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name ','Marks'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf8xy1s7-lLS",
        "outputId": "d492a304-a679-4df7-f57e-0813318d54cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name : string, Marks: int]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting some columns from pyspark\n",
        "df_pyspark.select(['Name ','Marks']).show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNqSkudZ-sFX",
        "outputId": "7e7fdc9c-ad1d-4ed2-9c1c-8c1ed26074cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "| Name |Marks|\n",
            "+------+-----+\n",
            "|  Mike|   80|\n",
            "|Jacson|   30|\n",
            "|Thomas|   78|\n",
            "+------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark['Name ']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twrDLVe0-vaZ",
        "outputId": "382f5f87-6d13-44dc-bd1c-ecdddfeac5e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name '>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNy5HHdn_GOy",
        "outputId": "b3f63ff6-4c63-44f3-e1d6-9ccb7f6c3d0b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Student', 'int'),\n",
              " ('Name ', 'string'),\n",
              " ('Subject', 'string'),\n",
              " ('Marks', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSCQD1xD_huL",
        "outputId": "9d4232fe-95d5-4ebe-ccf1-a5fde002e804"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Student: integer (nullable = true)\n",
            " |-- Name : string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Marks: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9dZOZTG_kLY",
        "outputId": "532b3218-e32a-40d4-dda4-3b455a0f0bfe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+------+-------+-----------------+\n",
            "|summary|          Student| Name |Subject|            Marks|\n",
            "+-------+-----------------+------+-------+-----------------+\n",
            "|  count|                8|     8|      8|                5|\n",
            "|   mean|              4.5|  NULL|   NULL|             66.2|\n",
            "| stddev|2.449489742783178|  NULL|   NULL|28.81319142337412|\n",
            "|    min|                1|   Amy|  Maths|               30|\n",
            "|    max|                8|Thomas|Science|              100|\n",
            "+-------+-----------------+------+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding columns in dataframe\n",
        "\n",
        "df_pyspark.withColumn('Marks+10',df_pyspark['Marks']+10).show(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly_Kv0rr_pQZ",
        "outputId": "906cf9ee-818b-472f-c984-559b09e60265"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+--------+\n",
            "|Student|   Name |Subject|Marks|Marks+10|\n",
            "+-------+--------+-------+-----+--------+\n",
            "|      1|    Mike|Physics|   80|      90|\n",
            "|      2|  Jacson|  Maths|   30|      40|\n",
            "|      3|  Thomas|Science|   78|      88|\n",
            "|      4|    Lisa|Physics| NULL|    NULL|\n",
            "|      5|     Amy|  Maths|   43|      53|\n",
            "|      6|Jennifer|Science| NULL|    NULL|\n",
            "|      7|   Karen|Physics|  100|     110|\n",
            "|      8|     Ram|  Maths| NULL|    NULL|\n",
            "+-------+--------+-------+-----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here columns is not added. One need to write df_pyspark=df_pyspark.withColumn('total_rooms plus 1',df_pyspark['total_rooms']+1)\n",
        "df_pyspark.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_QJLEGiDsmO",
        "outputId": "a0933dbc-f5e9-47d7-ec4b-ed18d41e4731"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+-----+\n",
            "|Student| Name |Subject|Marks|\n",
            "+-------+------+-------+-----+\n",
            "|      1|  Mike|Physics|   80|\n",
            "|      2|Jacson|  Maths|   30|\n",
            "|      3|Thomas|Science|   78|\n",
            "+-------+------+-------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping a column\n",
        "df_pyspark.drop('Student').show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNQKxxPiDPP_",
        "outputId": "339459fd-0e29-4214-e870-55d2b981963d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+\n",
            "| Name |Subject|Marks|\n",
            "+------+-------+-----+\n",
            "|  Mike|Physics|   80|\n",
            "|Jacson|  Maths|   30|\n",
            "|Thomas|Science|   78|\n",
            "+------+-------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remaning a column\n",
        "\n",
        "df_pyspark.withColumnRenamed('Name ','Name1').show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPNjcLcvETt6",
        "outputId": "07e7a54b-653a-454c-cb24-2bbc92e1087a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+-----+\n",
            "|Student| Name1|Subject|Marks|\n",
            "+-------+------+-------+-----+\n",
            "|      1|  Mike|Physics|   80|\n",
            "|      2|Jacson|  Maths|   30|\n",
            "|      3|Thomas|Science|   78|\n",
            "+-------+------+-------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show(4)"
      ],
      "metadata": {
        "id": "3U43HU7SEgeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5737ae3-c199-4257-bee7-c0be586e1ca5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+-----+\n",
            "|Student| Name |Subject|Marks|\n",
            "+-------+------+-------+-----+\n",
            "|      1|  Mike|Physics|   80|\n",
            "|      2|Jacson|  Maths|   30|\n",
            "|      3|Thomas|Science|   78|\n",
            "|      4|  Lisa|Physics| NULL|\n",
            "+-------+------+-------+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.drop('Marks').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2gkmCsVsrtt",
        "outputId": "1106796f-f835-4f86-db1f-38ce6580ce14"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+\n",
            "|Student| Name |Subject|\n",
            "+-------+------+-------+\n",
            "|      1|  Mike|Physics|\n",
            "|      2|Jacson|  Maths|\n",
            "|      3|Thomas|Science|\n",
            "|      4|  Lisa|Physics|\n",
            "|      5|   Amy|  Maths|\n",
            "+-------+------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdyyoO71Xrb3",
        "outputId": "1a9d9465-6236-4439-d607-bfdc3cfd5a8d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# na.drop will drop the rows which contain null\n",
        "df_pyspark.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txaNCEt2sxha",
        "outputId": "fba57d3a-4256-4295-b574-5797b09525fe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-------+-----+\n",
            "|Student| Name |Subject|Marks|\n",
            "+-------+------+-------+-----+\n",
            "|      1|  Mike|Physics|   80|\n",
            "|      2|Jacson|  Maths|   30|\n",
            "|      3|Thomas|Science|   78|\n",
            "|      5|   Amy|  Maths|   43|\n",
            "|      7| Karen|Physics|  100|\n",
            "+-------+------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# na.drop(how='any') will drop the record if in contains any nulls. Irrespective of number of nulls in the row.\n",
        "# na.drop(how='all') will drop the record if all the values are null.\n",
        "# na.drop(how='any',thresh=2) --> It means that atleast 2 not null value should be present.\n",
        "# na.drop(how='any',subset=['median_house_value']) --> This will drop records with median_house_value as null\n",
        "df_pyspark.na.drop(how='any',thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GNI4oigtAkp",
        "outputId": "c16d093e-5558-436f-b2bb-7642d58a2c16"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling missing value\n",
        "df_pyspark.na.fill(100).show() #This will replace any missing value/null with \"XXX\"\n",
        "df_pyspark.na.fill(\"100\",'Marks').show() #This will replace all missing value in longitude to XXX\n",
        "df_pyspark.na.fill(\"100\",['Name ','Marks']).show() #This will replace all missing value in longitude and langitude column to XXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt5e1BCFweFe",
        "outputId": "1af02580-ae40-41e5-abde-86692266cb84"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics|  100|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science|  100|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths|  100|\n",
            "+-------+--------+-------+-----+\n",
            "\n",
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n",
            "+-------+--------+-------+-----+\n",
            "|Student|   Name |Subject|Marks|\n",
            "+-------+--------+-------+-----+\n",
            "|      1|    Mike|Physics|   80|\n",
            "|      2|  Jacson|  Maths|   30|\n",
            "|      3|  Thomas|Science|   78|\n",
            "|      4|    Lisa|Physics| NULL|\n",
            "|      5|     Amy|  Maths|   43|\n",
            "|      6|Jennifer|Science| NULL|\n",
            "|      7|   Karen|Physics|  100|\n",
            "|      8|     Ram|  Maths| NULL|\n",
            "+-------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDOk_-GqJs3f",
        "outputId": "f57ee03b-0f81-40a7-8428-e123822be382"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Student', 'string'),\n",
              " ('Name ', 'string'),\n",
              " ('Subject', 'string'),\n",
              " ('Marks', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "imputer=Imputer(inputCols=['Marks'],\n",
        "                outputCols=[\"{}_imputed\".format(c) for c in ['Marks']]).setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "MuIIXqTexqRe"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(df_spark).transform(df_spark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_qhmazNIodf",
        "outputId": "88319992-c70e-4e87-a036-7b6363ad196f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+-------+-----+-------------+\n",
            "|Student|   Name |Subject|Marks|Marks_imputed|\n",
            "+-------+--------+-------+-----+-------------+\n",
            "|      1|    Mike|Physics|   80|           80|\n",
            "|      2|  Jacson|  Maths|   30|           30|\n",
            "|      3|  Thomas|Science|   78|           78|\n",
            "|      4|    Lisa|Physics| NULL|           66|\n",
            "|      5|     Amy|  Maths|   43|           43|\n",
            "|      6|Jennifer|Science| NULL|           66|\n",
            "|      7|   Karen|Physics|  100|          100|\n",
            "|      8|     Ram|  Maths| NULL|           66|\n",
            "+-------+--------+-------+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kYIVtu71JnN_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}